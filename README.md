# ğŸŒâš–ï¸ AI Ethics Assignment â€” Designing Responsible and Fair AI Systems

This project explores **ethical AI design**, focusing on fairness, transparency, and accountability using IBMâ€™s **AI Fairness 360** toolkit.  
The goal is to audit and mitigate bias in real-world datasets â€” specifically the **COMPAS Recidivism Dataset** â€” and demonstrate practical ethical principles for AI.

---

## ğŸ§  Overview

AI systems influence decisions about credit, employment, and justice.  
Without ethical safeguards, they risk reinforcing human bias.  
This assignment follows **EU AI Ethics Guidelines** emphasizing:
- **Fairness**
- **Transparency**
- **Explainability**
- **Accountability**
- **Human agency and oversight**

---

## ğŸ“Š Dataset

**Dataset Used:** COMPAS Recidivism Dataset  
**Source:** [ProPublica Analysis](https://github.com/propublica/compas-analysis)

The dataset contains demographic and criminal history information about defendants used to predict reoffending likelihood.

---

## âš™ï¸ Project Structure

```
ai-ethics-assignment/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ compas-scores-two-years.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_fairness_audit.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ audit_fairness.py
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ AI_Ethics_Assignment_Report.md
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§© Installation

```bash
# Clone the repository
git clone https://github.com/<your-username>/ai-ethics-assignment.git
cd ai-ethics-assignment

# Create a virtual environment
python -m venv venv
source venv/Scripts/activate  # on Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ Usage

```bash
# Run the audit script
python src/audit_fairness.py
```

or open the notebook:

```bash
jupyter notebook notebooks/01_fairness_audit.ipynb
```

---

## ğŸ“ˆ Example Results

**Classification Report:**
```
              precision    recall  f1-score   support
0.0             0.68      0.74      0.71      1012
1.0             0.65      0.58      0.61       839
accuracy        0.67
```

**Fairness Metrics:**
```
Before Mitigation:
 - Mean difference: -0.097
 - Disparate impact: 0.840

After Mitigation (Reweighing):
 - Mean difference: 0.000
 - Disparate impact: 1.000
```

---

## ğŸ§® Tools Used

- **Python 3.12**
- **AI Fairness 360**
- **Scikit-learn**
- **Pandas / Matplotlib**
- **Jupyter Notebook**

---

## âš–ï¸ Ethical Guidelines Applied

- **Justice:** Ensuring equal outcomes across groups.  
- **Non-maleficence:** Avoiding harm via biased predictions.  
- **Autonomy:** Respecting individualsâ€™ data rights.  
- **Sustainability:** Responsible compute and data use.

---

## ğŸª„ Author
**Bikila Keneni**  
AI for Software Engineering â€” PLP Academy  
Â© 2025

---

## ğŸ“œ License
MIT License Â© 2025 Bikila Keneni
